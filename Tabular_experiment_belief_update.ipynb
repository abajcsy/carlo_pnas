{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d84b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# choise of the hypothesis will make problem hard \n",
    "# convergence. \n",
    "\n",
    "#      $_ @ _ % _ *  row experiment\n",
    "# player 1 hypothesis: player 2 catches me                 or goes to [6] intrinsically\n",
    "# player 2 hypothesis: player 1 wants to guide me to [6]   or goes to [0] intrinsically\n",
    "size_s = 7\n",
    "size_state_space = 7*7\n",
    "action_list = [-1, 0, 1] # moves left or right\n",
    "start_position_1 = 2 # position @\n",
    "start_position_2 = 4 # position %\n",
    "def dynamics(x1, x2, u1, u2):\n",
    "    x1_next = x1 + action_list[u1]\n",
    "    x2_next = x2 + action_list[u2]\n",
    "    if x1_next > 6 or x1_next < 0:\n",
    "        x1_next = x1\n",
    "    if x2_next > 6 or x2_next < 0:\n",
    "        x2_next = x2\n",
    "    x = x1_next*7+x2_next\n",
    "    return x\n",
    "\n",
    "p1_h1 = lambda x1, x2, u1, u2 : (x1-x2)**2  + 0.1*(u2-1)**2+ 0.1*(u1-1)**2      # reward for player 2\n",
    "p1_h2 = lambda x1, x2, u1, u2 : (x2-6)**2   + 0.1*(u2-1)**2+ 0.1*(u1-1)**2       # reward for player 2\n",
    "p2_h1 = lambda x1, x2, u1, u2 : (x2-6)**2   + 0.1*(u1-1)**2+ 0.1*(u2-1)**2     # reward for player 1\n",
    "p2_h2 = lambda x1, x2, u1, u2 : (x1)**2     + 0.1*(u1-1)**2+ 0.1*(u2-1)**2         # reward for player 1\n",
    "def value_functions(r1,r2,horizon, size_s):\n",
    "    NE_is_not_unique=False\n",
    "    Q1  = np.zeros((horizon-1, size_s**2, 3, 3))\n",
    "    Q2  = np.zeros((horizon-1, size_s**2, 3, 3))\n",
    "    pi1 = np.zeros((horizon-1, size_s**2), int)\n",
    "    pi2 = np.zeros((horizon-1, size_s**2), int)\n",
    "    V1  = np.zeros((horizon,   size_s**2))\n",
    "    V2  = np.zeros((horizon,   size_s**2))\n",
    "    for x in range(size_s**2):\n",
    "        x1 = int(x/size_s)\n",
    "        x2 = x%size_s\n",
    "        V1[-1,x] = r1(x1, x2, 1, 1)\n",
    "        V2[-1,x] = r2(x1, x2, 1, 1)\n",
    "    for t in np.flip(range(horizon-1)):\n",
    "        for x in range(size_s**2):\n",
    "            x1 = int(x/size_s)\n",
    "            x2 = x%size_s\n",
    "            for u1 in range(3):\n",
    "                for u2 in range(3):\n",
    "                    Q1[t,x,u1,u2] = r1(x1,x2,u1,u2) + V1[t+1,dynamics(x1,x2,u1,u2)] # u1 corresponds to row\n",
    "                    Q2[t,x,u1,u2] = r2(x1,x2,u1,u2) + V2[t+1,dynamics(x1,x2,u1,u2)]\n",
    "            pi1_tmp = np.argmin(Q1[t,x,:,:], 1) # Given player 2's row action, what's my column action?\n",
    "            pi2_tmp = np.argmin(Q2[t,x,:,:], 0) # Given player 1's column action, what's my row action?\n",
    "            tmp1_list = np.array(([]), dtype=np.int64)\n",
    "            tmp2_list = np.array(([]), dtype=np.int64)\n",
    "            for idx in range(3):\n",
    "                \n",
    "                if pi1_tmp[pi2_tmp[idx]] == idx:\n",
    "                    tmp1_list = np.append(tmp1_list, idx)\n",
    "                    tmp2_list = np.append(tmp2_list, pi2_tmp[idx])    \n",
    "            if len(tmp1_list)>2:\n",
    "                NE_is_not_unique=True\n",
    "            elif len(tmp1_list)==0:\n",
    "                import pdb; pdb.set_trace()\n",
    "            pi2[t,x] = tmp1_list[0]\n",
    "            pi1[t,x] = tmp2_list[0]\n",
    "            \n",
    "            V1[t,x] = Q1[t, x, pi1[t,x], pi2[t,x]]\n",
    "            V2[t,x] = Q2[t, x, pi1[t,x], pi2[t,x]]     \n",
    "    print(\"NE is not unique.\") if NE_is_not_unique==True else None\n",
    "    return V1, V2, Q1, Q2, pi1, pi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798e8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "# player 1 hypothesis: player 2 catches me                 or goes to [6] intrinsically\n",
    "# player 2 hypothesis: player 1 wants to guide me to [6]   or goes to [0] intrinsically\n",
    "V1_1, V2_1, Q1_1, Q2_1, pi1_1, pi2_1 = value_functions(p2_h1,p1_h1,horizon, size_s) # ground truth\n",
    "V1_2, V2_2, Q1_2, Q2_2, pi1_2, pi2_2 = value_functions(p2_h2,p1_h1,horizon, size_s) # in player 2's mind\n",
    "V1_3, V2_3, Q1_3, Q2_3, pi1_3, pi2_3 = value_functions(p2_h1,p1_h2,horizon, size_s) # in player 1's mind\n",
    "V1_4, V2_4, Q1_4, Q2_4, pi1_4, pi2_4 = value_functions(p2_h2,p1_h2,horizon, size_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bccf9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled trajectory:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [4, 4],\n",
       "       [5, 5],\n",
       "       [6, 6],\n",
       "       [6, 6],\n",
       "       [6, 6],\n",
       "       [6, 6],\n",
       "       [6, 6],\n",
       "       [6, 6],\n",
       "       [6, 6],\n",
       "       [6, 6],\n",
       "       [6, 6]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulation under ground truth cost parameters\n",
    "x1 = 3\n",
    "x2 = 3\n",
    "\n",
    "x_traj = np.zeros(horizon, int)\n",
    "x_traj[0] = x1*7 + x2\n",
    "x_list = np.zeros((horizon,2), int)\n",
    "x_list[0,0] = x1\n",
    "x_list[0,1] = x2\n",
    "for t in range(horizon-1):\n",
    "    action1 = pi1_1[t,int(x_traj[t])]\n",
    "    action2 = pi2_1[t,int(x_traj[t])]\n",
    "    x_traj[t+1] = dynamics(x_list[t,0],x_list[t,1], action1, action2)\n",
    "    x_list[t+1,0] = int(x_traj[t+1]/size_s)\n",
    "    x_list[t+1,1] = x_traj[t+1]%size_s\n",
    "print(\"sampled trajectory:\")\n",
    "x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e74bc3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled trajectory:\n",
      "[[3 3]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "# in player 2's mind: I want to catch player 1, player 1 wants to go to [0]\n",
    "x1=3\n",
    "x2=3\n",
    "\n",
    "x_traj = np.zeros(horizon, int)\n",
    "x_traj[0] = x1*7 + x2\n",
    "x_list = np.zeros((horizon,2), int)\n",
    "x_list[0,0] = x1\n",
    "x_list[0,1] = x2\n",
    "for t in range(horizon-1):\n",
    "    action1 = pi1_2[t,int(x_traj[t])]\n",
    "    action2 = pi2_2[t,int(x_traj[t])]\n",
    "    x_traj[t+1] = dynamics(x_list[t,0],x_list[t,1], action1, action2)\n",
    "    x_list[t+1,0] = int(x_traj[t+1]/size_s)\n",
    "    x_list[t+1,1] = x_traj[t+1]%size_s\n",
    "print(\"sampled trajectory:\")\n",
    "print(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b32d3a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled trajectory:\n",
      "[[3 3]\n",
      " [3 4]\n",
      " [3 5]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "# in player 1's mind: I want to guide player 2 to [6], player 2 wants to go to [6]\n",
    "x1 = 3\n",
    "x2 = 3\n",
    "\n",
    "x_traj = np.zeros(horizon, int)\n",
    "x_traj[0] = x1*7 + x2\n",
    "x_list = np.zeros((horizon,2), int)\n",
    "x_list[0,0] = x1\n",
    "x_list[0,1] = x2\n",
    "for t in range(horizon-1):\n",
    "    action1 = pi1_3[t,int(x_traj[t])]\n",
    "    action2 = pi2_3[t,int(x_traj[t])]\n",
    "    x_traj[t+1] = dynamics(x_list[t,0],x_list[t,1], action1, action2)\n",
    "    x_list[t+1,0] = int(x_traj[t+1]/size_s)\n",
    "    x_list[t+1,1] = x_traj[t+1]%size_s\n",
    "print(\"sampled trajectory:\")\n",
    "print(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a79e4610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled trajectory:\n",
      "[[3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]\n",
      " [3 3]]\n"
     ]
    }
   ],
   "source": [
    "# simulation never happens\n",
    "x1 = 3\n",
    "x2 = 3\n",
    "\n",
    "x_traj = np.zeros(horizon, int)\n",
    "x_traj[0] = x1*7 + x2\n",
    "x_list = np.zeros((horizon,2), int)\n",
    "x_list[0,0] = x1\n",
    "x_list[0,1] = x2\n",
    "for t in range(horizon-1):\n",
    "    action1 = pi1_4[t,int(x_traj[t])]\n",
    "    action2 = pi2_4[t,int(x_traj[t])]\n",
    "    x_traj[t+1] = dynamics(x_list[t,0],x_list[t,1], action1, action2)\n",
    "    x_list[t+1,0] = int(x_traj[t+1]/size_s)\n",
    "    x_list[t+1,1] = x_traj[t+1]%size_s\n",
    "print(\"sampled trajectory:\")\n",
    "print(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "845ed3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define belief update rule:\n",
    "# player 1's task policy: pi1_3,  observation: u2=pi2_2(t,x),  update belief according to: pi2_3\n",
    "# player 2's task policy: pi2_2,  observation: u1=pi1_3(t,x),  update belief according to: pi1_2\n",
    "x1=3\n",
    "x2=3\n",
    "def belief_update_p1(prior, u2, t, x):\n",
    "    if prior == 1:\n",
    "        if u2!=pi2_3[t,x]:\n",
    "            posterior = 0\n",
    "        else:\n",
    "            posterior = 1\n",
    "    else:\n",
    "        if u2!=pi2_1[t,x]:\n",
    "            posterior = 1\n",
    "        else:\n",
    "            posterior = 0\n",
    "    return posterior\n",
    "def belief_update_p2(prior, u1, t, x):\n",
    "    if prior == 1:\n",
    "        if u1!=pi1_2[t,x]:\n",
    "            posterior = 0\n",
    "        else:\n",
    "            posterior = 1\n",
    "    else:\n",
    "        if u1!=pi1_1[t,x]:\n",
    "            posterior = 1\n",
    "        else:\n",
    "            posterior = 0\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75521fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll-out trajectory\n",
    "x1=3                                     # initial state of player 1\n",
    "x2=3                                     # initial state of player 2\n",
    "x_traj_list = np.zeros((horizon,2), int) # state trajectory, understandable by human\n",
    "x_combined = np.zeros(horizon, int)      # state trajectory, understandable by computer\n",
    "x_traj_list[0,0] = x1                    # initial condition of player 1\n",
    "x_traj_list[0,1] = x2                    # initial condition of player 2\n",
    "x_combined[0] = x1*7+x2                  \n",
    "b1_list = np.zeros(horizon, int)         # player 1's belief \n",
    "b2_list = np.zeros(horizon, int)         # player 2's belief\n",
    "b1_list[0] = 1                           # player 1's initial belief\n",
    "b2_list[0] = 0                           # player 2's initial belief\n",
    "u1_list=np.zeros(horizon-1, int)         # player 1's control trajectory\n",
    "u2_list=np.zeros(horizon-1, int)         # player 2's control trajectory\n",
    "\n",
    "for t in range(horizon-1):\n",
    "    policy_of_player1 = pi1_1 if b1_list[t] == 0 else pi1_3\n",
    "    policy_of_player2 = pi2_1 if b2_list[t] == 0 else pi2_2\n",
    "    u1_list[t] = policy_of_player1[t,x_combined[t]]\n",
    "    u2_list[t] = policy_of_player2[t,x_combined[t]]\n",
    "    \n",
    "    x_combined[t+1] = dynamics(x_traj_list[t,0], x_traj_list[t,1],u1_list[t],u2_list[t])\n",
    "    x_traj_list[t+1,0] = int(x_combined[t+1]/size_s)\n",
    "    x_traj_list[t+1,1] = x_combined[t+1]%size_s\n",
    "    \n",
    "    b1_list[t+1] = belief_update_p1(b1_list[t], u2_list[t], t,x_combined[t])\n",
    "    b2_list[t+1] = belief_update_p2(b2_list[t], u1_list[t], t,x_combined[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "044a4bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player 1's belief evolution:\n",
      "[1 1 0 1 1 0 0 0 0 0 0 0]\n",
      "player 2's belief evolution:\n",
      "[0 1 1 0 1 0 0 0 0 0 0 0]\n",
      "roll-out trajectory with belief update:\n",
      "[[3 3]\n",
      " [3 4]\n",
      " [3 3]\n",
      " [4 2]\n",
      " [4 3]\n",
      " [4 3]\n",
      " [4 4]\n",
      " [5 5]\n",
      " [6 6]\n",
      " [6 6]\n",
      " [6 6]\n",
      " [6 6]]\n"
     ]
    }
   ],
   "source": [
    "# player 1's belief converges as time goes. Initial belief: b1 = 1 \\in {0,1}\n",
    "print(\"player 1's belief evolution:\")\n",
    "print(b1_list)\n",
    "# player 2's belief converges as time goes. Initial belief: b2 = 0 \\in {0,1}\n",
    "print(\"player 2's belief evolution:\")\n",
    "print(b2_list)\n",
    "# simulated state trajectories of player 1 and player 2. Initial state x1[0] = 3, x2[0] = 3.\n",
    "print(\"roll-out trajectory with belief update:\")\n",
    "print(x_traj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c0f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
